{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (38,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "Train = pd.read_csv(\"Train_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19731 entries, 0 to 19730\n",
      "Data columns (total 51 columns):\n",
      "Unnamed: 0               19731 non-null int64\n",
      "Agreement_ID             19731 non-null int64\n",
      "Foreclosure              19731 non-null int64\n",
      "Customer_ID              19731 non-null int64\n",
      "MOB                      19731 non-null int64\n",
      "Loan_Amt                 19731 non-null object\n",
      "NET_DISBURSED_AMT        19731 non-null object\n",
      "Interest_Start_Date      19731 non-null object\n",
      "Current_ROI              19731 non-null float64\n",
      "Original_ROI             19731 non-null float64\n",
      "Current_Tenure           19731 non-null float64\n",
      "Original_Tenure          19731 non-null int64\n",
      "Due_Day                  19731 non-null int64\n",
      "Authorization_Date       19731 non-null object\n",
      "City                     19731 non-null object\n",
      "Pre_EMI_Due_Amt          19731 non-null float64\n",
      "Pre_EMI_Received_Amt     19731 non-null float64\n",
      "PRE_EMI_OS_AMOUNT        19731 non-null float64\n",
      "EMI_Due_Amt              19731 non-null float64\n",
      "EMI_Received_Amt         19731 non-null float64\n",
      "EMI_OS_AMOUNT            19731 non-null float64\n",
      "Excess_Available         19731 non-null float64\n",
      "Excess_Adjusted_Amt      19731 non-null float64\n",
      "Balance_Excess           19731 non-null float64\n",
      "Net_Receivable           19731 non-null float64\n",
      "Outstanding_Principal    19731 non-null float64\n",
      "Paid_Principal           19731 non-null float64\n",
      "Paid_Interest            19731 non-null float64\n",
      "Month_Opening            19731 non-null float64\n",
      "Last_Receipt_Date        19663 non-null object\n",
      "LAST_RECEIPT_AMOUNT      19514 non-null float64\n",
      "Net_LTV                  19731 non-null float64\n",
      "Completed_Tenure         19731 non-null int64\n",
      "Balance_Tenure           19731 non-null float64\n",
      "DPD                      19731 non-null float64\n",
      "FOIR                     19731 non-null float64\n",
      "Product                  19731 non-null object\n",
      "Scheme_ID                19731 non-null float64\n",
      "NPA_In_Last_Month        127 non-null object\n",
      "NPA_In_Current_Month     127 non-null object\n",
      "Cust_Const_Type_ID       5992 non-null float64\n",
      "Cust_Category_ID         5992 non-null float64\n",
      "Age                      5746 non-null float64\n",
      "Gender                   5747 non-null object\n",
      "Marital_Status           5746 non-null object\n",
      "Qualification            5742 non-null object\n",
      "No_Of_Dependent          5949 non-null float64\n",
      "Gross_Income             5992 non-null float64\n",
      "Pre_Job_Years            1407 non-null float64\n",
      "Net_Take_Home_Income     5992 non-null float64\n",
      "Branch_Pincode           5949 non-null float64\n",
      "dtypes: float64(31), int64(8), object(12)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_Amt</th>\n",
       "      <th>NET_DISBURSED_AMT</th>\n",
       "      <th>Interest_Start_Date</th>\n",
       "      <th>Authorization_Date</th>\n",
       "      <th>City</th>\n",
       "      <th>Last_Receipt_Date</th>\n",
       "      <th>Product</th>\n",
       "      <th>NPA_In_Last_Month</th>\n",
       "      <th>NPA_In_Current_Month</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Qualification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,17,10,107.24</td>\n",
       "      <td>1,17,10,107.24</td>\n",
       "      <td>30-Aug-10</td>\n",
       "      <td>29-Aug-10</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>05-May-14</td>\n",
       "      <td>HL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>POSTGRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,92,90,253.32</td>\n",
       "      <td>1,92,90,253.32</td>\n",
       "      <td>15-Sep-10</td>\n",
       "      <td>15-Sep-10</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>01-Nov-13</td>\n",
       "      <td>HL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>POSTGRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39,33,395.00</td>\n",
       "      <td>39,33,395.00</td>\n",
       "      <td>01-Nov-10</td>\n",
       "      <td>02-Nov-10</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>05-Aug-17</td>\n",
       "      <td>HL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>GRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,00,22,587.71</td>\n",
       "      <td>1,00,22,587.71</td>\n",
       "      <td>06-Oct-10</td>\n",
       "      <td>06-Oct-10</td>\n",
       "      <td>THANE</td>\n",
       "      <td>02-May-18</td>\n",
       "      <td>HL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>POSTGRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77,55,937.31</td>\n",
       "      <td>77,55,937.31</td>\n",
       "      <td>26-Oct-10</td>\n",
       "      <td>26-Oct-10</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>05-Apr-18</td>\n",
       "      <td>HL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Loan_Amt NET_DISBURSED_AMT Interest_Start_Date Authorization_Date  \\\n",
       "0   1,17,10,107.24    1,17,10,107.24            30-Aug-10          29-Aug-10   \n",
       "1   1,92,90,253.32    1,92,90,253.32            15-Sep-10          15-Sep-10   \n",
       "2     39,33,395.00      39,33,395.00            01-Nov-10          02-Nov-10   \n",
       "3   1,00,22,587.71    1,00,22,587.71            06-Oct-10          06-Oct-10   \n",
       "4     77,55,937.31      77,55,937.31            26-Oct-10          26-Oct-10   \n",
       "\n",
       "     City Last_Receipt_Date Product NPA_In_Last_Month NPA_In_Current_Month  \\\n",
       "0  MUMBAI         05-May-14      HL               NaN                  NaN   \n",
       "1  MUMBAI         01-Nov-13      HL               NaN                  NaN   \n",
       "2  MUMBAI         05-Aug-17      HL               NaN                  NaN   \n",
       "3   THANE         02-May-18      HL               NaN                  NaN   \n",
       "4  MUMBAI         05-Apr-18      HL               NaN                  NaN   \n",
       "\n",
       "  Gender Marital_Status Qualification  \n",
       "0      M              M      POSTGRAD  \n",
       "1      M              M      POSTGRAD  \n",
       "2      M              M          GRAD  \n",
       "3      M              M      POSTGRAD  \n",
       "4      M              M            UG  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# encode categorical variables using Label Encoder\n",
    "\n",
    "# select all categorical variables\n",
    "df_categorical = Train.select_dtypes(include=['object'])\n",
    "df_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainX_merged = pd.read_csv(\"TrainX_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_categorical = df_categorical[['City','Product','Gender','Marital_Status','Qualification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_categorical.Gender = df_categorical.Gender.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_categorical.Marital_Status = df_categorical.Marital_Status.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_categorical.Qualification = df_categorical.Qualification.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Product</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Qualification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City  Product  Gender  Marital_Status  Qualification\n",
       "0   145        0       1               0              5\n",
       "1   145        0       1               0              5\n",
       "2   145        0       1               0              2\n",
       "3   222        0       1               0              5\n",
       "4   145        0       1               0              7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply Label encoder to df_categorical\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_categorical = df_categorical.apply(le.fit_transform)\n",
    "df_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_data = pd.concat([TrainX_merged, df_categorical],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_data = Train_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Amt_DF = Train.loc[:,['Pre_EMI_Due_Amt','Pre_EMI_Received_Amt','PRE_EMI_OS_AMOUNT','EMI_Due_Amt',\n",
    "                          'EMI_Received_Amt' ,'EMI_OS_AMOUNT','Excess_Available',\n",
    "                            'Excess_Adjusted_Amt','Balance_Excess','Net_Receivable','Outstanding_Principal'\n",
    "                            ,'Paid_Principal','Paid_Interest','Month_Opening']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_Amt_DF = round(Train_Amt_DF/100000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_data = pd.concat([Train_data,Train_Amt_DF],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_Numeric = Train.loc[:,['DPD','FOIR','No_Of_Dependent'\n",
    "                            ,'Pre_Job_Years']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_data = pd.concat([Train_data,Train_Numeric],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19731 entries, 0 to 19730\n",
      "Data columns (total 29 columns):\n",
      "Net_Disbursed_Amt        19731 non-null float64\n",
      "ROI_Change_Ratio         19731 non-null float64\n",
      "Tenure_Ratio             19731 non-null float64\n",
      "Tenure_Change_Ratio      19731 non-null float64\n",
      "Foreclosure              19731 non-null int64\n",
      "Net_LTV                  19731 non-null float64\n",
      "City                     19731 non-null int32\n",
      "Product                  19731 non-null int32\n",
      "Gender                   19731 non-null int32\n",
      "Marital_Status           19731 non-null int32\n",
      "Qualification            19731 non-null int32\n",
      "Pre_EMI_Due_Amt          19731 non-null float64\n",
      "Pre_EMI_Received_Amt     19731 non-null float64\n",
      "PRE_EMI_OS_AMOUNT        19731 non-null float64\n",
      "EMI_Due_Amt              19731 non-null float64\n",
      "EMI_Received_Amt         19731 non-null float64\n",
      "EMI_OS_AMOUNT            19731 non-null float64\n",
      "Excess_Available         19731 non-null float64\n",
      "Excess_Adjusted_Amt      19731 non-null float64\n",
      "Balance_Excess           19731 non-null float64\n",
      "Net_Receivable           19731 non-null float64\n",
      "Outstanding_Principal    19731 non-null float64\n",
      "Paid_Principal           19731 non-null float64\n",
      "Paid_Interest            19731 non-null float64\n",
      "Month_Opening            19731 non-null float64\n",
      "DPD                      19731 non-null float64\n",
      "FOIR                     19731 non-null float64\n",
      "No_Of_Dependent          5949 non-null float64\n",
      "Pre_Job_Years            1407 non-null float64\n",
      "dtypes: float64(23), int32(5), int64(1)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "Train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_Of_Dependent</th>\n",
       "      <th>Pre_Job_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5949.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.522609</td>\n",
       "      <td>4.607676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.102681</td>\n",
       "      <td>6.443729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       No_Of_Dependent  Pre_Job_Years\n",
       "count      5949.000000    1407.000000\n",
       "mean          0.522609       4.607676\n",
       "std           1.102681       6.443729\n",
       "min           0.000000       0.000000\n",
       "25%           0.000000       0.000000\n",
       "50%           0.000000       2.000000\n",
       "75%           0.000000       7.000000\n",
       "max          10.000000      37.000000"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data[['No_Of_Dependent','Pre_Job_Years']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data['No_Of_Dependent'] = Train_data['No_Of_Dependent'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_data['Pre_Job_Years'] = Train_data['Pre_Job_Years'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing train-test-split \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = Train_data.drop(['Foreclosure'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = Train_data['Foreclosure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net_Disbursed_Amt</th>\n",
       "      <th>ROI_Change_Ratio</th>\n",
       "      <th>Tenure_Ratio</th>\n",
       "      <th>Tenure_Change_Ratio</th>\n",
       "      <th>Net_LTV</th>\n",
       "      <th>City</th>\n",
       "      <th>Product</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Balance_Excess</th>\n",
       "      <th>Net_Receivable</th>\n",
       "      <th>Outstanding_Principal</th>\n",
       "      <th>Paid_Principal</th>\n",
       "      <th>Paid_Interest</th>\n",
       "      <th>Month_Opening</th>\n",
       "      <th>DPD</th>\n",
       "      <th>FOIR</th>\n",
       "      <th>No_Of_Dependent</th>\n",
       "      <th>Pre_Job_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16257</th>\n",
       "      <td>13.51</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>37.83</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>30.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.92</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>23.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.12</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>27.58</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>73.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16897</th>\n",
       "      <td>15.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85.15</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Net_Disbursed_Amt  ROI_Change_Ratio  Tenure_Ratio  Tenure_Change_Ratio  \\\n",
       "16257              13.51             -0.10          0.02                -0.17   \n",
       "7515               30.03              0.00          0.10                 0.00   \n",
       "1993               23.87              0.00          0.05                 0.00   \n",
       "2239               27.58             -0.04          0.22                -0.03   \n",
       "16897              15.51              0.00          0.03                 0.00   \n",
       "\n",
       "       Net_LTV  City  Product  Gender  Marital_Status  Qualification  \\\n",
       "16257    37.83   261        1       2               2              8   \n",
       "7515     70.92    90        2       1               1              7   \n",
       "1993     54.12    90        2       0               0              5   \n",
       "2239     73.06     2        0       1               0              7   \n",
       "16897    85.15   247        2       2               2              8   \n",
       "\n",
       "           ...        Balance_Excess  Net_Receivable  Outstanding_Principal  \\\n",
       "16257      ...                   0.0             0.0                   13.0   \n",
       "7515       ...                   0.0             0.0                   29.0   \n",
       "1993       ...                   0.0             0.0                   23.0   \n",
       "2239       ...                   0.0             0.0                   25.0   \n",
       "16897      ...                   0.0             0.0                   15.0   \n",
       "\n",
       "       Paid_Principal  Paid_Interest  Month_Opening  DPD  FOIR  \\\n",
       "16257             0.0            1.0           13.0  0.0  0.57   \n",
       "7515              1.0            7.0           29.0  0.0  0.30   \n",
       "1993              0.0            3.0           23.0  0.0  0.49   \n",
       "2239              3.0           13.0           25.0  0.0  0.49   \n",
       "16897             0.0            1.0           15.0  0.0  0.34   \n",
       "\n",
       "       No_Of_Dependent  Pre_Job_Years  \n",
       "16257             -1.0           -1.0  \n",
       "7515               0.0           -1.0  \n",
       "1993               0.0           -1.0  \n",
       "2239               2.0           -1.0  \n",
       "16897             -1.0           -1.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state = 99)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing decision tree classifier from sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Fitting the decision tree with default hyperparameters, apart from\n",
    "# max_depth which is 5 so that we can plot and read the tree.\n",
    "dt_default = DecisionTreeClassifier(max_depth=5)\n",
    "dt_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      5354\n",
      "           1       0.65      0.57      0.61       566\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5920\n",
      "   macro avg       0.80      0.77      0.78      5920\n",
      "weighted avg       0.93      0.93      0.93      5920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "\n",
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "y_pred_default = dt_default.predict(X_test)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5179  175]\n",
      " [ 242  324]]\n",
      "0.9295608108108108\n"
     ]
    }
   ],
   "source": [
    "# Printing confusion matrix and accuracy\n",
    "print(confusion_matrix(y_test,y_pred_default))\n",
    "print(accuracy_score(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(1, 40)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='precision',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal max_depth\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(1, 40)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"precision\")\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015842</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025674</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.650152</td>\n",
       "      <td>0.644450</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.660504</td>\n",
       "      <td>0.625767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629870</td>\n",
       "      <td>0.647343</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.624809</td>\n",
       "      <td>0.655844</td>\n",
       "      <td>0.640902</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.051821</td>\n",
       "      <td>0.011683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.831466</td>\n",
       "      <td>0.842511</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.660504</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.843658</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.893281</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.906780</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.126006</td>\n",
       "      <td>0.093988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036294</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.684330</td>\n",
       "      <td>0.708426</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.675824</td>\n",
       "      <td>0.709576</td>\n",
       "      <td>0.635802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.723869</td>\n",
       "      <td>0.751592</td>\n",
       "      <td>0.672293</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.715210</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.038892</td>\n",
       "      <td>0.018731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.673765</td>\n",
       "      <td>0.702344</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>0.735149</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659898</td>\n",
       "      <td>0.692491</td>\n",
       "      <td>0.738372</td>\n",
       "      <td>0.752420</td>\n",
       "      <td>0.655963</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.035633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.051543</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.687030</td>\n",
       "      <td>0.763184</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.682464</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712042</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.717489</td>\n",
       "      <td>0.746432</td>\n",
       "      <td>0.676617</td>\n",
       "      <td>0.758312</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.025774</td>\n",
       "      <td>0.022715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050753</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.719250</td>\n",
       "      <td>0.824784</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.705584</td>\n",
       "      <td>0.821664</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.823834</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.836927</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.852018</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>0.020720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.063384</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.694305</td>\n",
       "      <td>0.847769</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.874005</td>\n",
       "      <td>0.709845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.850560</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.840387</td>\n",
       "      <td>0.655963</td>\n",
       "      <td>0.810384</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.023998</td>\n",
       "      <td>0.021891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.069587</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.706898</td>\n",
       "      <td>0.888355</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.912985</td>\n",
       "      <td>0.686636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732984</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.706806</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.693780</td>\n",
       "      <td>0.861988</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.019707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.071381</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.706997</td>\n",
       "      <td>0.907174</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.673171</td>\n",
       "      <td>0.900235</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711443</td>\n",
       "      <td>0.906634</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.024538</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.015842         0.005423         0.000000          0.000000   \n",
       "1       0.025674         0.002206         0.650152          0.644450   \n",
       "2       0.029484         0.001797         0.831466          0.842511   \n",
       "3       0.036294         0.002214         0.684330          0.708426   \n",
       "4       0.050949         0.002007         0.673765          0.702344   \n",
       "5       0.051543         0.002615         0.687030          0.763184   \n",
       "6       0.050753         0.002210         0.719250          0.824784   \n",
       "7       0.063384         0.002607         0.694305          0.847769   \n",
       "8       0.069587         0.002811         0.706898          0.888355   \n",
       "9       0.071381         0.002006         0.706997          0.907174   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "0               1   {'max_depth': 1}               39           0.000000   \n",
       "1               2   {'max_depth': 2}               13           0.593407   \n",
       "2               3   {'max_depth': 3}                1           0.593407   \n",
       "3               4   {'max_depth': 4}                9           0.675824   \n",
       "4               5   {'max_depth': 5}               11           0.702830   \n",
       "5               6   {'max_depth': 6}                7           0.682464   \n",
       "6               7   {'max_depth': 7}                2           0.705584   \n",
       "7               8   {'max_depth': 8}                5           0.726776   \n",
       "8               9   {'max_depth': 9}                4           0.714286   \n",
       "9              10  {'max_depth': 10}                3           0.673171   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.000000           0.000000       ...                  0.000000   \n",
       "1            0.660504           0.625767       ...                  0.629870   \n",
       "2            0.660504           0.885246       ...                  0.828125   \n",
       "3            0.709576           0.635802       ...                  0.695946   \n",
       "4            0.735149           0.611765       ...                  0.659898   \n",
       "5            0.790123           0.646552       ...                  0.712042   \n",
       "6            0.821664           0.688372       ...                  0.747368   \n",
       "7            0.874005           0.709845       ...                  0.695238   \n",
       "8            0.912985           0.686636       ...                  0.732984   \n",
       "9            0.900235           0.715000       ...                  0.711443   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.000000           0.000000            0.000000   \n",
       "1            0.647343           0.745902            0.624809   \n",
       "2            0.843658           0.958333            0.893281   \n",
       "3            0.723869           0.751592            0.672293   \n",
       "4            0.692491           0.738372            0.752420   \n",
       "5            0.788235           0.717489            0.746432   \n",
       "6            0.823834           0.709497            0.836927   \n",
       "7            0.850560           0.683673            0.840387   \n",
       "8            0.904000           0.706806            0.893617   \n",
       "9            0.906634           0.745562            0.917808   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.000000            0.000000      0.001609        0.006326   \n",
       "1           0.655844            0.640902      0.004150        0.000401   \n",
       "2           0.892308            0.906780      0.002057        0.000405   \n",
       "3           0.662500            0.715210      0.001319        0.000980   \n",
       "4           0.655963            0.666667      0.002718        0.000002   \n",
       "5           0.676617            0.758312      0.004237        0.000812   \n",
       "6           0.745455            0.852018      0.001743        0.000386   \n",
       "7           0.655963            0.810384      0.004227        0.000480   \n",
       "8           0.693780            0.861988      0.005139        0.000746   \n",
       "9           0.689815            0.885417      0.008663        0.000634   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.000000         0.000000  \n",
       "1        0.051821         0.011683  \n",
       "2        0.126006         0.093988  \n",
       "3        0.038892         0.018731  \n",
       "4        0.043297         0.035633  \n",
       "5        0.025774         0.022715  \n",
       "6        0.023292         0.020720  \n",
       "7        0.023998         0.021891  \n",
       "8        0.016234         0.019707  \n",
       "9        0.024538         0.014007  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH9BSLbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'min_samples_leaf': range(5, 200, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal max_depth\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(5, 200, 20)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"precision\")\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075207</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.684411</td>\n",
       "      <td>0.882384</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_samples_leaf': 5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.668182</td>\n",
       "      <td>0.886034</td>\n",
       "      <td>0.675799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701835</td>\n",
       "      <td>0.871767</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.888255</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.878348</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.006374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060384</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.700788</td>\n",
       "      <td>0.779855</td>\n",
       "      <td>25</td>\n",
       "      <td>{'min_samples_leaf': 25}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.677273</td>\n",
       "      <td>0.778835</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728205</td>\n",
       "      <td>0.796818</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>0.788438</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.772889</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.042347</td>\n",
       "      <td>0.011994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057753</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.694014</td>\n",
       "      <td>0.752333</td>\n",
       "      <td>45</td>\n",
       "      <td>{'min_samples_leaf': 45}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.675556</td>\n",
       "      <td>0.743743</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725888</td>\n",
       "      <td>0.728211</td>\n",
       "      <td>0.668317</td>\n",
       "      <td>0.746411</td>\n",
       "      <td>0.728205</td>\n",
       "      <td>0.758398</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.027072</td>\n",
       "      <td>0.018911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052551</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.700283</td>\n",
       "      <td>0.738863</td>\n",
       "      <td>65</td>\n",
       "      <td>{'min_samples_leaf': 65}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.765753</td>\n",
       "      <td>0.678756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711230</td>\n",
       "      <td>0.727833</td>\n",
       "      <td>0.712042</td>\n",
       "      <td>0.742785</td>\n",
       "      <td>0.678947</td>\n",
       "      <td>0.714810</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.017791</td>\n",
       "      <td>0.017070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057151</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.701589</td>\n",
       "      <td>0.732815</td>\n",
       "      <td>85</td>\n",
       "      <td>{'min_samples_leaf': 85}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699482</td>\n",
       "      <td>0.743836</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715976</td>\n",
       "      <td>0.746763</td>\n",
       "      <td>0.693122</td>\n",
       "      <td>0.715507</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.725955</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.011517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.075207         0.002405         0.684411          0.882384   \n",
       "1       0.060384         0.002002         0.700788          0.779855   \n",
       "2       0.057753         0.001814         0.694014          0.752333   \n",
       "3       0.052551         0.002000         0.700283          0.738863   \n",
       "4       0.057151         0.003010         0.701589          0.732815   \n",
       "\n",
       "  param_min_samples_leaf                    params  rank_test_score  \\\n",
       "0                      5   {'min_samples_leaf': 5}                6   \n",
       "1                     25  {'min_samples_leaf': 25}                2   \n",
       "2                     45  {'min_samples_leaf': 45}                4   \n",
       "3                     65  {'min_samples_leaf': 65}                3   \n",
       "4                     85  {'min_samples_leaf': 85}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.668182            0.886034           0.675799       ...          \n",
       "1           0.677273            0.778835           0.628319       ...          \n",
       "2           0.675556            0.743743           0.672131       ...          \n",
       "3           0.720430            0.765753           0.678756       ...          \n",
       "4           0.699482            0.743836           0.704918       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.701835            0.871767           0.703518   \n",
       "1           0.728205            0.796818           0.740331   \n",
       "2           0.725888            0.728211           0.668317   \n",
       "3           0.711230            0.727833           0.712042   \n",
       "4           0.715976            0.746763           0.693122   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.888255           0.672727            0.878348      0.005558   \n",
       "1            0.788438           0.729858            0.772889      0.001723   \n",
       "2            0.746411           0.728205            0.758398      0.001623   \n",
       "3            0.742785           0.678947            0.714810      0.001869   \n",
       "4            0.715507           0.694444            0.725955      0.005108   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000480        0.015118         0.006374  \n",
       "1        0.000622        0.042347         0.011994  \n",
       "2        0.000405        0.027072         0.018911  \n",
       "3        0.000012        0.017791         0.017070  \n",
       "4        0.001089        0.008309         0.011517  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAELCAYAAAAoUKpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'min_samples_split': range(5, 200, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(5, 200, 20)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"precision\")\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083431</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.626353</td>\n",
       "      <td>0.975146</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_samples_split': 5}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.630081</td>\n",
       "      <td>0.973629</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>0.970244</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>0.976521</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.978791</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.023144</td>\n",
       "      <td>0.002948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.078604</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.679780</td>\n",
       "      <td>0.871784</td>\n",
       "      <td>25</td>\n",
       "      <td>{'min_samples_split': 25}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.663507</td>\n",
       "      <td>0.884024</td>\n",
       "      <td>0.665138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688995</td>\n",
       "      <td>0.854626</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.880866</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.873126</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.010572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086238</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.695613</td>\n",
       "      <td>0.833998</td>\n",
       "      <td>45</td>\n",
       "      <td>{'min_samples_split': 45}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.853904</td>\n",
       "      <td>0.641350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690821</td>\n",
       "      <td>0.845789</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.834515</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.828605</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.033986</td>\n",
       "      <td>0.016026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079819</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.675712</td>\n",
       "      <td>0.802829</td>\n",
       "      <td>65</td>\n",
       "      <td>{'min_samples_split': 65}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.662037</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.815545</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.788419</td>\n",
       "      <td>0.710784</td>\n",
       "      <td>0.810174</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.023028</td>\n",
       "      <td>0.009415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075203</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.686901</td>\n",
       "      <td>0.787529</td>\n",
       "      <td>85</td>\n",
       "      <td>{'min_samples_split': 85}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.688119</td>\n",
       "      <td>0.819462</td>\n",
       "      <td>0.638211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656522</td>\n",
       "      <td>0.772678</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.794012</td>\n",
       "      <td>0.721951</td>\n",
       "      <td>0.795343</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.035659</td>\n",
       "      <td>0.021578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.069395</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.681185</td>\n",
       "      <td>0.767101</td>\n",
       "      <td>105</td>\n",
       "      <td>{'min_samples_split': 105}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.798976</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659389</td>\n",
       "      <td>0.738943</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.683486</td>\n",
       "      <td>0.769412</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.020275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.071005</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.687144</td>\n",
       "      <td>0.760274</td>\n",
       "      <td>125</td>\n",
       "      <td>{'min_samples_split': 125}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.712821</td>\n",
       "      <td>0.804781</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656522</td>\n",
       "      <td>0.733405</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.758343</td>\n",
       "      <td>0.687783</td>\n",
       "      <td>0.736607</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.030420</td>\n",
       "      <td>0.025807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.069792</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.705273</td>\n",
       "      <td>0.774917</td>\n",
       "      <td>145</td>\n",
       "      <td>{'min_samples_split': 145}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.706161</td>\n",
       "      <td>0.777914</td>\n",
       "      <td>0.650224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707182</td>\n",
       "      <td>0.782904</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.802539</td>\n",
       "      <td>0.712821</td>\n",
       "      <td>0.757306</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.017814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.072605</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>0.773696</td>\n",
       "      <td>165</td>\n",
       "      <td>{'min_samples_split': 165}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.800550</td>\n",
       "      <td>0.637066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725714</td>\n",
       "      <td>0.784341</td>\n",
       "      <td>0.763514</td>\n",
       "      <td>0.832803</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>0.746053</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.042536</td>\n",
       "      <td>0.044381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.069190</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.710902</td>\n",
       "      <td>0.762823</td>\n",
       "      <td>185</td>\n",
       "      <td>{'min_samples_split': 185}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.718593</td>\n",
       "      <td>0.764557</td>\n",
       "      <td>0.641129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.766484</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.708108</td>\n",
       "      <td>0.744401</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.041789</td>\n",
       "      <td>0.040397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.083431         0.002404         0.626353          0.975146   \n",
       "1       0.078604         0.002406         0.679780          0.871784   \n",
       "2       0.086238         0.002608         0.695613          0.833998   \n",
       "3       0.079819         0.002202         0.675712          0.802829   \n",
       "4       0.075203         0.002412         0.686901          0.787529   \n",
       "5       0.069395         0.002007         0.681185          0.767101   \n",
       "6       0.071005         0.002005         0.687144          0.760274   \n",
       "7       0.069792         0.002011         0.705273          0.774917   \n",
       "8       0.072605         0.002199         0.713143          0.773696   \n",
       "9       0.069190         0.002211         0.710902          0.762823   \n",
       "\n",
       "  param_min_samples_split                      params  rank_test_score  \\\n",
       "0                       5    {'min_samples_split': 5}               10   \n",
       "1                      25   {'min_samples_split': 25}                8   \n",
       "2                      45   {'min_samples_split': 45}                4   \n",
       "3                      65   {'min_samples_split': 65}                9   \n",
       "4                      85   {'min_samples_split': 85}                6   \n",
       "5                     105  {'min_samples_split': 105}                7   \n",
       "6                     125  {'min_samples_split': 125}                5   \n",
       "7                     145  {'min_samples_split': 145}                3   \n",
       "8                     165  {'min_samples_split': 165}                1   \n",
       "9                     185  {'min_samples_split': 185}                2   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.630081            0.973629           0.633333       ...          \n",
       "1           0.663507            0.884024           0.665138       ...          \n",
       "2           0.684729            0.853904           0.641350       ...          \n",
       "3           0.662037            0.801402           0.649351       ...          \n",
       "4           0.688119            0.819462           0.638211       ...          \n",
       "5           0.710000            0.798976           0.628571       ...          \n",
       "6           0.712821            0.804781           0.650442       ...          \n",
       "7           0.706161            0.777914           0.650224       ...          \n",
       "8           0.735135            0.800550           0.637066       ...          \n",
       "9           0.718593            0.764557           0.641129       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.654867            0.970244           0.629464   \n",
       "1           0.688995            0.854626           0.729885   \n",
       "2           0.690821            0.845789           0.741573   \n",
       "3           0.694444            0.815545           0.661972   \n",
       "4           0.656522            0.772678           0.729730   \n",
       "5           0.659389            0.738943           0.724490   \n",
       "6           0.656522            0.733405           0.728155   \n",
       "7           0.707182            0.782904           0.750000   \n",
       "8           0.725714            0.784341           0.763514   \n",
       "9           0.714286            0.766484           0.772414   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.976521           0.584000            0.978791      0.003726   \n",
       "1            0.880866           0.651376            0.873126      0.004114   \n",
       "2            0.834515           0.719626            0.828605      0.002448   \n",
       "3            0.788419           0.710784            0.810174      0.008170   \n",
       "4            0.794012           0.721951            0.795343      0.006462   \n",
       "5            0.774648           0.683486            0.769412      0.001617   \n",
       "6            0.758343           0.687783            0.736607      0.003922   \n",
       "7            0.802539           0.712821            0.757306      0.002166   \n",
       "8            0.832803           0.704301            0.746053      0.005683   \n",
       "9            0.831461           0.708108            0.744401      0.001263   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000487        0.023144         0.002948  \n",
       "1        0.001004        0.027860         0.010572  \n",
       "2        0.001211        0.033986         0.016026  \n",
       "3        0.000393        0.023028         0.009415  \n",
       "4        0.000812        0.035659         0.021578  \n",
       "5        0.000002        0.034511         0.020275  \n",
       "6        0.000014        0.030420         0.025807  \n",
       "7        0.000011        0.031915         0.017814  \n",
       "8        0.000387        0.042536         0.044381  \n",
       "9        0.000399        0.041789         0.040397  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAELCAYAAAAoUKpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+GVhYYwxxi8LC2OMMX79f8IJbZ880RIHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(5, 15, 5), 'min_samples_leaf': range(50, 150, 50), 'min_samples_split': range(50, 150, 50), 'criterion': ['entropy', 'gini']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "    'criterion': [\"entropy\", \"gini\"]\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n",
    "                          cv = n_folds, verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\SharmilaK1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048931</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.935848</td>\n",
       "      <td>0.939813</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931209</td>\n",
       "      <td>0.940176</td>\n",
       "      <td>0.936640</td>\n",
       "      <td>0.942076</td>\n",
       "      <td>0.935168</td>\n",
       "      <td>0.937195</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042518</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.935848</td>\n",
       "      <td>0.939813</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931209</td>\n",
       "      <td>0.940176</td>\n",
       "      <td>0.936640</td>\n",
       "      <td>0.942076</td>\n",
       "      <td>0.935168</td>\n",
       "      <td>0.937195</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049130</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.934835</td>\n",
       "      <td>0.938835</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931571</td>\n",
       "      <td>0.939995</td>\n",
       "      <td>0.935554</td>\n",
       "      <td>0.939271</td>\n",
       "      <td>0.932633</td>\n",
       "      <td>0.936923</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.001854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044511</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.934835</td>\n",
       "      <td>0.938835</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931571</td>\n",
       "      <td>0.939995</td>\n",
       "      <td>0.935554</td>\n",
       "      <td>0.939271</td>\n",
       "      <td>0.932633</td>\n",
       "      <td>0.936923</td>\n",
       "      <td>0.005688</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.001854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053348</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.938962</td>\n",
       "      <td>0.946528</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940261</td>\n",
       "      <td>0.947416</td>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.946330</td>\n",
       "      <td>0.941326</td>\n",
       "      <td>0.945973</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.057763</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.938962</td>\n",
       "      <td>0.946528</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940261</td>\n",
       "      <td>0.947416</td>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.946330</td>\n",
       "      <td>0.941326</td>\n",
       "      <td>0.945973</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.045515</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.937948</td>\n",
       "      <td>0.941188</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936278</td>\n",
       "      <td>0.943796</td>\n",
       "      <td>0.935554</td>\n",
       "      <td>0.939271</td>\n",
       "      <td>0.936255</td>\n",
       "      <td>0.940995</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045921</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.937948</td>\n",
       "      <td>0.941188</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936278</td>\n",
       "      <td>0.943796</td>\n",
       "      <td>0.935554</td>\n",
       "      <td>0.939271</td>\n",
       "      <td>0.936255</td>\n",
       "      <td>0.940995</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039116</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.936355</td>\n",
       "      <td>0.939740</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931209</td>\n",
       "      <td>0.938546</td>\n",
       "      <td>0.938450</td>\n",
       "      <td>0.941714</td>\n",
       "      <td>0.935893</td>\n",
       "      <td>0.937557</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.037520</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.936862</td>\n",
       "      <td>0.939740</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0.938546</td>\n",
       "      <td>0.938450</td>\n",
       "      <td>0.941714</td>\n",
       "      <td>0.935893</td>\n",
       "      <td>0.937557</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.036708</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.936934</td>\n",
       "      <td>0.939125</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932657</td>\n",
       "      <td>0.937913</td>\n",
       "      <td>0.940261</td>\n",
       "      <td>0.940719</td>\n",
       "      <td>0.933720</td>\n",
       "      <td>0.937285</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.001642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.936934</td>\n",
       "      <td>0.939125</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932657</td>\n",
       "      <td>0.937913</td>\n",
       "      <td>0.940261</td>\n",
       "      <td>0.940719</td>\n",
       "      <td>0.933720</td>\n",
       "      <td>0.937285</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.001642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.047732</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.939251</td>\n",
       "      <td>0.946365</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938088</td>\n",
       "      <td>0.945515</td>\n",
       "      <td>0.939537</td>\n",
       "      <td>0.947054</td>\n",
       "      <td>0.943861</td>\n",
       "      <td>0.945792</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.046526</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.939758</td>\n",
       "      <td>0.946365</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940623</td>\n",
       "      <td>0.945515</td>\n",
       "      <td>0.939537</td>\n",
       "      <td>0.947054</td>\n",
       "      <td>0.943861</td>\n",
       "      <td>0.945792</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.041128</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>0.940935</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937002</td>\n",
       "      <td>0.941352</td>\n",
       "      <td>0.940261</td>\n",
       "      <td>0.940719</td>\n",
       "      <td>0.936617</td>\n",
       "      <td>0.941086</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.040918</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>0.940935</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937002</td>\n",
       "      <td>0.941352</td>\n",
       "      <td>0.940261</td>\n",
       "      <td>0.940719</td>\n",
       "      <td>0.936617</td>\n",
       "      <td>0.941086</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.000496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.048931         0.001605         0.935848          0.939813   \n",
       "1        0.042518         0.001805         0.935848          0.939813   \n",
       "2        0.049130         0.002006         0.934835          0.938835   \n",
       "3        0.044511         0.001806         0.934835          0.938835   \n",
       "4        0.053348         0.001204         0.938962          0.946528   \n",
       "5        0.057763         0.001803         0.938962          0.946528   \n",
       "6        0.045515         0.001608         0.937948          0.941188   \n",
       "7        0.045921         0.001399         0.937948          0.941188   \n",
       "8        0.039116         0.001805         0.936355          0.939740   \n",
       "9        0.037520         0.001199         0.936862          0.939740   \n",
       "10       0.036708         0.001810         0.936934          0.939125   \n",
       "11       0.035505         0.001404         0.936934          0.939125   \n",
       "12       0.047732         0.001208         0.939251          0.946365   \n",
       "13       0.046526         0.001411         0.939758          0.946365   \n",
       "14       0.041128         0.001608         0.939107          0.940935   \n",
       "15       0.040918         0.001609         0.939107          0.940935   \n",
       "\n",
       "   param_criterion param_max_depth param_min_samples_leaf  \\\n",
       "0          entropy               5                     50   \n",
       "1          entropy               5                     50   \n",
       "2          entropy               5                    100   \n",
       "3          entropy               5                    100   \n",
       "4          entropy              10                     50   \n",
       "5          entropy              10                     50   \n",
       "6          entropy              10                    100   \n",
       "7          entropy              10                    100   \n",
       "8             gini               5                     50   \n",
       "9             gini               5                     50   \n",
       "10            gini               5                    100   \n",
       "11            gini               5                    100   \n",
       "12            gini              10                     50   \n",
       "13            gini              10                     50   \n",
       "14            gini              10                    100   \n",
       "15            gini              10                    100   \n",
       "\n",
       "   param_min_samples_split                                             params  \\\n",
       "0                       50  {'criterion': 'entropy', 'max_depth': 5, 'min_...   \n",
       "1                      100  {'criterion': 'entropy', 'max_depth': 5, 'min_...   \n",
       "2                       50  {'criterion': 'entropy', 'max_depth': 5, 'min_...   \n",
       "3                      100  {'criterion': 'entropy', 'max_depth': 5, 'min_...   \n",
       "4                       50  {'criterion': 'entropy', 'max_depth': 10, 'min...   \n",
       "5                      100  {'criterion': 'entropy', 'max_depth': 10, 'min...   \n",
       "6                       50  {'criterion': 'entropy', 'max_depth': 10, 'min...   \n",
       "7                      100  {'criterion': 'entropy', 'max_depth': 10, 'min...   \n",
       "8                       50  {'criterion': 'gini', 'max_depth': 5, 'min_sam...   \n",
       "9                      100  {'criterion': 'gini', 'max_depth': 5, 'min_sam...   \n",
       "10                      50  {'criterion': 'gini', 'max_depth': 5, 'min_sam...   \n",
       "11                     100  {'criterion': 'gini', 'max_depth': 5, 'min_sam...   \n",
       "12                      50  {'criterion': 'gini', 'max_depth': 10, 'min_sa...   \n",
       "13                     100  {'criterion': 'gini', 'max_depth': 10, 'min_sa...   \n",
       "14                      50  {'criterion': 'gini', 'max_depth': 10, 'min_sa...   \n",
       "15                     100  {'criterion': 'gini', 'max_depth': 10, 'min_sa...   \n",
       "\n",
       "    rank_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0                13       ...                  0.931209            0.940176   \n",
       "1                13       ...                  0.931209            0.940176   \n",
       "2                15       ...                  0.931571            0.939995   \n",
       "3                15       ...                  0.931571            0.939995   \n",
       "4                 5       ...                  0.940261            0.947416   \n",
       "5                 5       ...                  0.940261            0.947416   \n",
       "6                 7       ...                  0.936278            0.943796   \n",
       "7                 7       ...                  0.936278            0.943796   \n",
       "8                12       ...                  0.931209            0.938546   \n",
       "9                11       ...                  0.933744            0.938546   \n",
       "10                9       ...                  0.932657            0.937913   \n",
       "11                9       ...                  0.932657            0.937913   \n",
       "12                2       ...                  0.938088            0.945515   \n",
       "13                1       ...                  0.940623            0.945515   \n",
       "14                3       ...                  0.937002            0.941352   \n",
       "15                3       ...                  0.937002            0.941352   \n",
       "\n",
       "    split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0            0.936640            0.942076           0.935168   \n",
       "1            0.936640            0.942076           0.935168   \n",
       "2            0.935554            0.939271           0.932633   \n",
       "3            0.935554            0.939271           0.932633   \n",
       "4            0.935192            0.946330           0.941326   \n",
       "5            0.935192            0.946330           0.941326   \n",
       "6            0.935554            0.939271           0.936255   \n",
       "7            0.935554            0.939271           0.936255   \n",
       "8            0.938450            0.941714           0.935893   \n",
       "9            0.938450            0.941714           0.935893   \n",
       "10           0.940261            0.940719           0.933720   \n",
       "11           0.940261            0.940719           0.933720   \n",
       "12           0.939537            0.947054           0.943861   \n",
       "13           0.939537            0.947054           0.943861   \n",
       "14           0.940261            0.940719           0.936617   \n",
       "15           0.940261            0.940719           0.936617   \n",
       "\n",
       "    split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0             0.937195      0.008999        0.000496        0.004853   \n",
       "1             0.937195      0.003389        0.000401        0.004853   \n",
       "2             0.936923      0.002286        0.000634        0.005448   \n",
       "3             0.936923      0.005688        0.001607        0.005448   \n",
       "4             0.945973      0.004718        0.000401        0.003174   \n",
       "5             0.945973      0.003011        0.000400        0.003174   \n",
       "6             0.940995      0.001865        0.000494        0.003538   \n",
       "7             0.940995      0.001482        0.000496        0.003538   \n",
       "8             0.937557      0.001562        0.000751        0.004943   \n",
       "9             0.937557      0.001202        0.000396        0.004499   \n",
       "10            0.937285      0.004324        0.000759        0.004226   \n",
       "11            0.937285      0.001359        0.000491        0.004226   \n",
       "12            0.945792      0.001201        0.000399        0.004025   \n",
       "13            0.945792      0.000489        0.000486        0.004006   \n",
       "14            0.941086      0.000626        0.000485        0.002554   \n",
       "15            0.941086      0.000731        0.000484        0.002554   \n",
       "\n",
       "    std_train_score  \n",
       "0          0.002492  \n",
       "1          0.002492  \n",
       "2          0.001854  \n",
       "3          0.001854  \n",
       "4          0.000573  \n",
       "5          0.000573  \n",
       "6          0.001492  \n",
       "7          0.001492  \n",
       "8          0.002105  \n",
       "9          0.002105  \n",
       "10         0.001642  \n",
       "11         0.001642  \n",
       "12         0.000772  \n",
       "13         0.000772  \n",
       "14         0.000496  \n",
       "15         0.000496  \n",
       "\n",
       "[16 rows x 24 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy 0.9397581637824922\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print(\"best accuracy\", grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=85, min_samples_split=165,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model with optimal hyperparameters\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state = 100,\n",
    "                                  max_depth=3, \n",
    "                                  min_samples_leaf=85,\n",
    "                                  min_samples_split=165)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'precision_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-186-9f3a7679cb79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# accuracy score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf_gini\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'precision_score'"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "clf_gini.precision_score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'edelweiss_decision_tree_model.sav'\n",
    "pickle.dump(clf_gini, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
